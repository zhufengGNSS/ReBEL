<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
                "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
  <title>Description of netunpak</title>
  <meta name="keywords" content="netunpak">
  <meta name="description" content="NETUNPAK Separates weights vector into weight and bias matrices.">
  <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
  <meta name="generator" content="m2html &copy; 2003 Guillaume Flandin">
  <meta name="robots" content="index, follow">
  <link type="text/css" rel="stylesheet" href="../../m2html.css">
</head>
<body>
<a name="_top"></a>
<div><a href="../../menu.html">Home</a> &gt;  <a href="#">ReBEL-0.2.7</a> &gt; <a href="#">netlab</a> &gt; netunpak.m</div>

<!--<table width="100%"><tr><td align="left"><a href="../../menu.html"><img alt="<" border="0" src="../../left.png">&nbsp;Master index</a></td>
<td align="right"><a href="menu.html">Index for .\ReBEL-0.2.7\netlab&nbsp;<img alt=">" border="0" src="../../right.png"></a></td></tr></table>-->

<h1>netunpak
</h1>

<h2><a name="_name"></a>PURPOSE <a href="#_top"><img alt="^" border="0" src="../../up.png"></a></h2>
<div class="box"><strong>NETUNPAK Separates weights vector into weight and bias matrices.</strong></div>

<h2><a name="_synopsis"></a>SYNOPSIS <a href="#_top"><img alt="^" border="0" src="../../up.png"></a></h2>
<div class="box"><strong>function net = netunpak(net, w) </strong></div>

<h2><a name="_description"></a>DESCRIPTION <a href="#_top"><img alt="^" border="0" src="../../up.png"></a></h2>
<div class="fragment"><pre class="comment">NETUNPAK Separates weights vector into weight and bias matrices. 

    Description
    NET = NETUNPAK(NET, W) takes an net network data structure NET and  a
    weight vector W, and returns a network data structure identical to
    the input network, except that the componenet weight matrices have
    all been set to the corresponding elements of W.  If there is  a MASK
    field in the NET data structure, then the weights in W are placed in
    locations corresponding to non-zero entries in the mask (so W should
    have the same length as the number of non-zero entries in the MASK).

    See also
    <a href="netpak.html" class="code" title="function w = netpak(net)">NETPAK</a>, NETFWD, <a href="neterr.html" class="code" title="function [e, varargout] = neterr(w, net, x, t)">NETERR</a>, <a href="netgrad.html" class="code" title="function g = netgrad(w, net, x, t)">NETGRAD</a></pre></div>

<!-- crossreference -->
<h2><a name="_cross"></a>CROSS-REFERENCE INFORMATION <a href="#_top"><img alt="^" border="0" src="../../up.png"></a></h2>
This function calls:
<ul style="list-style-image:url(../../matlabicon.gif)">
</ul>
This function is called by:
<ul style="list-style-image:url(../../matlabicon.gif)">
<li><a href="netderiv.html" class="code" title="function g = netderiv(w, net, x)">netderiv</a>	NETDERIV Evaluate derivatives of network outputs by weights generically.</li><li><a href="neterr.html" class="code" title="function [e, varargout] = neterr(w, net, x, t)">neterr</a>	NETERR	Evaluate network error function for generic optimizers</li><li><a href="netevfwd.html" class="code" title="function [y, extra, invhess] = netevfwd(w, net, x, t, x_test, invhess)">netevfwd</a>	NETEVFWD Generic forward propagation with evidence for network</li><li><a href="netgrad.html" class="code" title="function g = netgrad(w, net, x, t)">netgrad</a>	NETGRAD Evaluate network error gradient for generic optimizers</li><li><a href="nethess.html" class="code" title="function [h, varargout] = nethess(w, net, x, t, varargin)">nethess</a>	NETHESS Evaluate network Hessian</li><li><a href="netinit.html" class="code" title="function net = netinit(net, prior)">netinit</a>	NETINIT Initialise the weights in a network.</li><li><a href="netopt.html" class="code" title="function [net, options, varargout] = netopt(net, options, x, t, alg);">netopt</a>	NETOPT	Optimize the weights in a network model.</li><li><a href="rbftrain.html" class="code" title="function [net, options] = rbftrain(net, options, x, t)">rbftrain</a>	RBFTRAIN Two stage training of RBF network.</li></ul>
<!-- crossreference -->


<h2><a name="_source"></a>SOURCE CODE <a href="#_top"><img alt="^" border="0" src="../../up.png"></a></h2>
<div class="fragment"><pre>0001 <a name="_sub0" href="#_subfunctions" class="code">function net = netunpak(net, w)</a>
0002 <span class="comment">%NETUNPAK Separates weights vector into weight and bias matrices.</span>
0003 <span class="comment">%</span>
0004 <span class="comment">%    Description</span>
0005 <span class="comment">%    NET = NETUNPAK(NET, W) takes an net network data structure NET and  a</span>
0006 <span class="comment">%    weight vector W, and returns a network data structure identical to</span>
0007 <span class="comment">%    the input network, except that the componenet weight matrices have</span>
0008 <span class="comment">%    all been set to the corresponding elements of W.  If there is  a MASK</span>
0009 <span class="comment">%    field in the NET data structure, then the weights in W are placed in</span>
0010 <span class="comment">%    locations corresponding to non-zero entries in the mask (so W should</span>
0011 <span class="comment">%    have the same length as the number of non-zero entries in the MASK).</span>
0012 <span class="comment">%</span>
0013 <span class="comment">%    See also</span>
0014 <span class="comment">%    NETPAK, NETFWD, NETERR, NETGRAD</span>
0015 <span class="comment">%</span>
0016 
0017 <span class="comment">%    Copyright (c) Ian T Nabney (1996-2001)</span>
0018 
0019 unpakstr = [net.type, <span class="string">'unpak'</span>];
0020 
0021 <span class="comment">% Check if we are being passed a masked set of weights</span>
0022 <span class="keyword">if</span> (isfield(net, <span class="string">'mask'</span>))
0023    <span class="keyword">if</span> length(w) ~= size(find(net.mask), 1)
0024       error(<span class="string">'Weight vector length does not match mask length'</span>)
0025    <span class="keyword">end</span>
0026    <span class="comment">% Do a full pack of all current network weights</span>
0027    pakstr = [net.type, <span class="string">'pak'</span>];
0028    fullw = feval(pakstr, net);
0029    <span class="comment">% Replace current weights with new ones</span>
0030    fullw(logical(net.mask)) = w;
0031    w = fullw;
0032 <span class="keyword">end</span>
0033 
0034 net = feval(unpakstr, net, w);</pre></div>
<hr><address>Generated on Tue 26-Sep-2006 10:36:21 by <strong><a href="http://www.artefact.tk/software/matlab/m2html/">m2html</a></strong> &copy; 2003</address>
</body>
</html>