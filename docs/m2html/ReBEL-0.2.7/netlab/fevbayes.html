<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
                "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
  <title>Description of fevbayes</title>
  <meta name="keywords" content="fevbayes">
  <meta name="description" content="FEVBAYES Evaluate Bayesian regularisation for network forward propagation.">
  <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
  <meta name="generator" content="m2html &copy; 2003 Guillaume Flandin">
  <meta name="robots" content="index, follow">
  <link type="text/css" rel="stylesheet" href="../../m2html.css">
</head>
<body>
<a name="_top"></a>
<div><a href="../../menu.html">Home</a> &gt;  <a href="#">ReBEL-0.2.7</a> &gt; <a href="#">netlab</a> &gt; fevbayes.m</div>

<!--<table width="100%"><tr><td align="left"><a href="../../menu.html"><img alt="<" border="0" src="../../left.png">&nbsp;Master index</a></td>
<td align="right"><a href="menu.html">Index for .\ReBEL-0.2.7\netlab&nbsp;<img alt=">" border="0" src="../../right.png"></a></td></tr></table>-->

<h1>fevbayes
</h1>

<h2><a name="_name"></a>PURPOSE <a href="#_top"><img alt="^" border="0" src="../../up.png"></a></h2>
<div class="box"><strong>FEVBAYES Evaluate Bayesian regularisation for network forward propagation.</strong></div>

<h2><a name="_synopsis"></a>SYNOPSIS <a href="#_top"><img alt="^" border="0" src="../../up.png"></a></h2>
<div class="box"><strong>function [extra, invhess] = fevbayes(net, y, a, x, t, x_test, invhess) </strong></div>

<h2><a name="_description"></a>DESCRIPTION <a href="#_top"><img alt="^" border="0" src="../../up.png"></a></h2>
<div class="fragment"><pre class="comment">FEVBAYES Evaluate Bayesian regularisation for network forward propagation.

    Description
    EXTRA = FEVBAYES(NET, Y, A, X, T, X_TEST) takes a network data
    structure  NET together with a set of hidden unit activations A from
    test inputs X_TEST, training data inputs X and T and outputs a matrix
    of extra information EXTRA that consists of error bars (variance) for
    a regression problem or moderated outputs for a classification
    problem. The optional argument (and return value)  INVHESS is the
    inverse of the network Hessian computed on the training data inputs
    and targets.  Passing it in avoids recomputing it, which can be a
    significant saving for large training sets.

    This is called by network-specific functions such as MLPEVFWD which
    are needed since the return values (predictions and hidden unit
    activations) for different network types are in different orders (for
    good reasons).

    See also
    <a href="mlpevfwd.html" class="code" title="function [y, extra, invhess] = mlpevfwd(net, x, t, x_test, invhess)">MLPEVFWD</a>, <a href="rbfevfwd.html" class="code" title="function [y, extra, invhess] = rbfevfwd(net, x, t, x_test, invhess)">RBFEVFWD</a>, <a href="glmevfwd.html" class="code" title="function [y, extra, invhess] = glmevfwd(net, x, t, x_test, invhess)">GLMEVFWD</a></pre></div>

<!-- crossreference -->
<h2><a name="_cross"></a>CROSS-REFERENCE INFORMATION <a href="#_top"><img alt="^" border="0" src="../../up.png"></a></h2>
This function calls:
<ul style="list-style-image:url(../../matlabicon.gif)">
<li><a href="netderiv.html" class="code" title="function g = netderiv(w, net, x)">netderiv</a>	NETDERIV Evaluate derivatives of network outputs by weights generically.</li><li><a href="nethess.html" class="code" title="function [h, varargout] = nethess(w, net, x, t, varargin)">nethess</a>	NETHESS Evaluate network Hessian</li><li><a href="netpak.html" class="code" title="function w = netpak(net)">netpak</a>	NETPAK	Combines weights and biases into one weights vector.</li></ul>
This function is called by:
<ul style="list-style-image:url(../../matlabicon.gif)">
<li><a href="glmevfwd.html" class="code" title="function [y, extra, invhess] = glmevfwd(net, x, t, x_test, invhess)">glmevfwd</a>	GLMEVFWD Forward propagation with evidence for GLM</li><li><a href="mlpevfwd.html" class="code" title="function [y, extra, invhess] = mlpevfwd(net, x, t, x_test, invhess)">mlpevfwd</a>	MLPEVFWD Forward propagation with evidence for MLP</li><li><a href="rbfevfwd.html" class="code" title="function [y, extra, invhess] = rbfevfwd(net, x, t, x_test, invhess)">rbfevfwd</a>	RBFEVFWD Forward propagation with evidence for RBF</li></ul>
<!-- crossreference -->


<h2><a name="_source"></a>SOURCE CODE <a href="#_top"><img alt="^" border="0" src="../../up.png"></a></h2>
<div class="fragment"><pre>0001 <a name="_sub0" href="#_subfunctions" class="code">function [extra, invhess] = fevbayes(net, y, a, x, t, x_test, invhess)</a>
0002 <span class="comment">%FEVBAYES Evaluate Bayesian regularisation for network forward propagation.</span>
0003 <span class="comment">%</span>
0004 <span class="comment">%    Description</span>
0005 <span class="comment">%    EXTRA = FEVBAYES(NET, Y, A, X, T, X_TEST) takes a network data</span>
0006 <span class="comment">%    structure  NET together with a set of hidden unit activations A from</span>
0007 <span class="comment">%    test inputs X_TEST, training data inputs X and T and outputs a matrix</span>
0008 <span class="comment">%    of extra information EXTRA that consists of error bars (variance) for</span>
0009 <span class="comment">%    a regression problem or moderated outputs for a classification</span>
0010 <span class="comment">%    problem. The optional argument (and return value)  INVHESS is the</span>
0011 <span class="comment">%    inverse of the network Hessian computed on the training data inputs</span>
0012 <span class="comment">%    and targets.  Passing it in avoids recomputing it, which can be a</span>
0013 <span class="comment">%    significant saving for large training sets.</span>
0014 <span class="comment">%</span>
0015 <span class="comment">%    This is called by network-specific functions such as MLPEVFWD which</span>
0016 <span class="comment">%    are needed since the return values (predictions and hidden unit</span>
0017 <span class="comment">%    activations) for different network types are in different orders (for</span>
0018 <span class="comment">%    good reasons).</span>
0019 <span class="comment">%</span>
0020 <span class="comment">%    See also</span>
0021 <span class="comment">%    MLPEVFWD, RBFEVFWD, GLMEVFWD</span>
0022 <span class="comment">%</span>
0023 
0024 <span class="comment">%    Copyright (c) Ian T Nabney (1996-2001)</span>
0025 
0026 w = <a href="netpak.html" class="code" title="function w = netpak(net)">netpak</a>(net);
0027 g = <a href="netderiv.html" class="code" title="function g = netderiv(w, net, x)">netderiv</a>(w, net, x_test);
0028 <span class="keyword">if</span> nargin &lt; 7
0029   <span class="comment">% Need to compute inverse hessian</span>
0030   hess = <a href="nethess.html" class="code" title="function [h, varargout] = nethess(w, net, x, t, varargin)">nethess</a>(w, net, x, t);
0031   invhess = inv(hess);
0032 <span class="keyword">end</span>
0033 
0034 ntest = size(x_test, 1);
0035 var = zeros(ntest, 1);
0036 <span class="keyword">for</span> idx = 1:1:net.nout,
0037   <span class="keyword">for</span> n = 1:1:ntest,
0038     grad = squeeze(g(n,:,idx));
0039     var(n,idx) = grad*invhess*grad';  
0040   <span class="keyword">end</span>
0041 <span class="keyword">end</span>
0042 
0043 <span class="keyword">switch</span> net.outfn
0044     <span class="keyword">case</span> <span class="string">'linear'</span>
0045     <span class="comment">% extra is variance</span>
0046     extra = ones(size(var))./net.beta + var;
0047     <span class="keyword">case</span> <span class="string">'logistic'</span>
0048     <span class="comment">% extra is moderated output</span>
0049     kappa = 1./(sqrt(ones(size(var)) + (pi.*var)./8));
0050     extra = 1./(1 + exp(-kappa.*a));
0051     <span class="keyword">case</span> <span class="string">'softmax'</span>
0052     <span class="comment">% Use extended Mackay formula; beware that this may not</span>
0053     <span class="comment">% be very accurate</span>
0054     kappa = 1./(sqrt(ones(size(var)) + (pi.*var)./8));
0055     temp = exp(kappa.*a);
0056     extra = temp./(sum(temp, 2)*ones(1, net.nout));
0057     <span class="keyword">otherwise</span>
0058     error([<span class="string">'Unknown activation function '</span>, net.outfn]);
0059 <span class="keyword">end</span></pre></div>
<hr><address>Generated on Tue 26-Sep-2006 10:36:21 by <strong><a href="http://www.artefact.tk/software/matlab/m2html/">m2html</a></strong> &copy; 2003</address>
</body>
</html>